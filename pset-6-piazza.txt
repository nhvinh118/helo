Group by year with Django ORM

I need some guidance on grouping my FactReviews by year to calculate aggregate stats in the API.
My approach was to annotate the FactReview objects with their year, then group by that value and calculate what we need. But my `values().annotate()` is not doing the group-by step.
Doing this on FactReviews returns one item per original row
(Note that I'm summing the ID column just to illustrate the comparison with DimDate behavior)

In [16]: FactReview.objects.annotate(year=ExtractYear('date__date')).values('year').annotate(total=Sum('id'))
Out[16]: QuerySet [{'year': 2005, 'total': 13938}, {'year': 2005, 'total': 13939}, {'year': 2006, 'total': 13940}, {'year': 2006, 'total': 13941}, {'year': 2006, 'total': 13942}, {'year': 2006, 'total': 13943}, {'year': 2006, 'total': 13944}, {'year': 2006, 'total': 13945}, {'year': 2006, 'total': 13946}, {'year': 2006, 'total': 13947}, {'year': 2006, 'total': 13948}, {'year': 2006, 'total': 13949}, {'year': 2006, 'total': 13950}, {'year': 2006, 'total': 13951}, {'year': 2007, 'total': 13952}, {'year': 2007, 'total': 13953}, {'year': 2007, 'total': 13954}, {'year': 2007, 'total': 13955}, {'year': 2007, 'total': 13956}, {'year': 2007, 'total': 13957}, '...(remaining elements truncated)...']

But doing it with DimDate objects has the expected aggregating behavior.

In [15]: DimDate.objects.annotate(year=ExtractYear('date')).values('year').annotate(total=Sum('id'))
Out[15]: QuerySet [{'year': 2005, 'total': 39343}, {'year': 2006, 'total': 236142}, {'year': 2007, 'total': 827631}, {'year': 2008, 'total': 2414075}, {'year': 2009, 'total': 2908539}, {'year': 2010, 'total': 4119885}, {'year': 2011, 'total': 5551728}, {'year': 2012, 'total': 6290625}, {'year': 2013, 'total': 6974352}, {'year': 2014, 'total': 7578706}, {'year': 2015, 'total': 7880054}, {'year': 2016, 'total': 7990356}, {'year': 2017, 'total': 7671195}]

What am I missing? I'm guessing it has to do with annotating based on a foreign key?
EDIT: It was due to the behavior of `.values()` acting on an annotated column. Inserting an `order_by()` call before the aggregation did the trick:

FactReview.objects.annotate(year=ExtractYear("date__date")).order_by("year").annotate(total=...)

reference: https://stackoverflow.com/questions/43132917/in-django-orm-values-and-annotate-are-not-working-to-group-by
values followed by annotate worked for me.

base = FactReview.objects.all()
base.values(year=ExtractYear('date__date')).annotate(..)
In your query, my guess is annotate is feeding 1 output row to values, and values is not seeing the full table at once to group it by year. I could be mistaken here. 
========================================================================
byyear: # Group by year, sum all facts, calculate mean using the count
For the QuerySet, the comment in pset_6 reads, 
# Group by year, sum all facts, calculate mean using the count
I'm little confused for the expected outcome
say for eg:
I have following rows in FACT table
date           count    stars   useful   funny     cool
1/1/2019    5           3         2          0             0
1/31/2019  1           5         5          0             0
So byyear=2019, should it return
average = (sum of counts/number of rows) = (5+1)/2 = 3?
You don't want to average the counts, but you do want to use the sum of counts as the denominator for the average in the other columns.
~ An instructor (Aaron White
) endorsed this answer  ~
"ByYearSerailizer -> #return the averages, not the sum!
ByYear views -> # Group by year, sum all facts, calculate mean using the count"
So are we returning averages for stars, useful, cool, funny by doing something like this: ?
a. groupbyyear.(sum of stars/sum of counts) 
b. groupbyyear.(sum of useful/sum of counts) 
c. groupbyyear.(sum of funny/sum of counts) 
d. groupbyyear.(sum of cool/sum of counts) 
"For the ByYear viewset and serializer, you want to calculate the average fact per review (stars, funny, etc) using the summary stats you've collected."
so definitely we are returning averages for stars, useful, cool, funny.
and then pset_6 says
"This must happen on the DB side, and only return 1 row per year."
But the code to be filled is in the "views"? in class ByYear(ModelViewSet)?
How I interpreted "This must happen on the DB side, and only return 1 row per year."
"In the ViewSet part only use the Django QuerySet methods e.g. .annotate(), .values(), .order_by() and database functions e.g. Sum(), Count(), F(), but do not use pandas or dask functions to perform the aggregations and calculate the summary stats."
==================================================================
 Pset 6 Api -url part
I donâ€™t see the confide.urls file in my file tree. Do I need to create one by myself or it should be there as default?
I think you might be referring to the urls.py file in src/config folder, as mentioned in URLS section of the pset?
================================================================
DateSerializer returns int
On the url http://localhost:8000/yelp/api/, when I attempt to 
"by_year": "<a href="http://localhost:8000/yelp/api/by_year/">http://localhost:8000/yelp/api/by_year/</a>"
from the API Root, I get the (original error) AttributeError
'int' object has no attribute 'date'
It makes sense when I look at the other link,
"facts": "<a href="http://localhost:8000/yelp/api/facts/">http://localhost:8000/yelp/api/facts/</a>"
and see that the date fields are int, not date type:
Whereas
"dates": "<a href="http://localhost:8000/yelp/api/dates/">http://localhost:8000/yelp/api/dates/</a>"
correctly returns date types:
However-- when I access the 'date' field of
    FactSerializer in serializers.py from the shell, I see that the 'date' field is correctly displaying dates.
    'FactReview in models.py
I cannot figure out why 'date' field returns int. I tried many ideas e.g.
    in FactSerializer 'date_id' and 'id' fields also return same values as 'date'
    in Models I tried adding to_field='date'
    from FactReview, 
        def __str__(self):
            return str(self.date.date)
   ...
I think your displays are correct. The FactReview table contains a pointer to the DimDate table. So the "date id" in the FactReview table will be an int.  
In my display, I was seeing an additional "id" field in both FactReview and DimDate.  I believe the "id" is the same as primary key.
~ An instructor (Scott Gorlin
==============================================================
 sum() vs mean()
In the 'The DataMart' section,
"...calculate statistics about the average facts by date. Because this is a "Fact" table, we want all the facts to be summary statistics, ie the sum of all properties within that group.",
should we do the aggregation using sum() or mean()? 
I understood it as sum(), e.g.: 
grp = dsk.groupby('date').sum()
grp['count'] = dsk.groupby('date').size()
df = grp.compute()
Mean is not a summary stat because you can't add them back up later. If you later took the mean of the means they would not be weighted per volume of reviews during each day
==================================================================
Clarifications on FactReview, DimDate Model and ByYear
In my DimDate model I have the following fields/columns:
a) id
b) date (DateField format)
In my FactReview model, I have the following fields/columns.
a) id which links to DimDate model
b) count (number of reviews on each date)
c) stars (sum for each date)
d) useful (sum for each date)
e) funny (sum for each date)
f) cool (sum for each date)
g) date (for some reason I am seeing this entry which has the same value as id as you will see below. Looks redundant, but I am not able to get rid of this)
When I browse the API for a "subset/single partition" of yelp reviews, I see the following representations:
GET /yelp/api/date/
HTTP 200 OK
Allow: GET, POST, HEAD, OPTIONS
Content-Type: application/json
Vary: Accept

{
    "count": 2866,
    "next": "http://127.0.0.1:8000/yelp/api/date/?limit=10&offset=10",
    "previous": null,
    "results": [
        {
            "id": 1,
            "date": "2005-06-15"
        },
        {
            "id": 2,
            "date": "2005-11-07"
        },
      ....

GET /yelp/api/facts/
HTTP 200 OK
Allow: GET, POST, HEAD, OPTIONS
Content-Type: application/json
Vary: Accept

{
    "count": 2866,
    "next": "http://127.0.0.1:8000/yelp/api/facts/?limit=10&offset=10",
    "previous": null,
    "results": [
        {
            "id": 1,
            "count": 1,
            "stars": 2,
            "useful": 0,
            "funny": 0,
            "cool": 0,
            "date": 1
        },
        {
            "id": 2,
            "count": 1,
            "stars": 5,
            "useful": 3,
            "funny": 1,
            "cool": 3,
            "date": 2
        },
....

GET /yelp/api/by_year/

HTTP 200 OK
Allow: GET, POST, HEAD, OPTIONS
Content-Type: application/json
Vary: Accept

{
    "count": 13,
    "next": "http://127.0.0.1:8000/yelp/api/by_year/?limit=10&offset=10",
    "previous": null,
    "results": [
        {
            "year": "2005",
            "stars": 3,
            "useful": 1,
            "funny": 0,
            "cool": 1,
            "count": 2
        },
        {
            "year": "2006",
            "stars": 4,
            "useful": 2,
            "funny": 0,
            "cool": 0,
            "count": 13
        },
        {
            "year": "2007",
            "stars": 3,
            "useful": 1,
            "funny": 1,
            "cool": 1,
            "count": 47
        },
 ...
Are you sure it's actually linked vs just looking like they have the same values? Since they both autoincrement if you insert facts in date order they'll happen to have the same pk values!
==========================================================================
Question about the data_load
So I'm loading data into the database aggregations  in the following way:

    def insert_data(self):
        df = self.output().read_dask().compute()
        items = df.head().to_dict('index')
        fact_reviews = []
        for i in items:
            dm, created = DimDate.objects.get_or_create(date=i)
            fact_reviews.append(FactReview(date_id=dm.id, count=items[i]['review_id'], stars=items[i]['stars'], useful=items[i]['useful'], funny=items[i]['funny'], cool=items[i]['cool']))
        FactReview.objects.bulk_create(fact_reviews)

My question is, are we suppose to assume that this load will happen only one time and never again? Or is this suppose to be like a spooling AWS directory in a data streaming pipeline that we will run this data_load on a recurrent basis (perhaps daily)? The reason I ask is if its the latter, my unique DB constraint will fail if this is run more than once and I will have to check uniqueness before trying to insert a new FactReview and either update or ignore.
In the pset instructions, one suggestion given in the section (Loading Data) is:
You may want a way to flush the DB (eg
FactReview.objects.all().delete())
So, i guess a simple approach would be that we can do a fresh reload each time we execute load_reviews
Also, in the same section, the following suggestions can help make the DB code a lot more concise:
Use django batteries copiously. These may help:
You could try to build off loadddata (or not)
transactions.atomic
queryset.bulk_create
queryset.in_bulk
Ideally you would have a way to update a time slice atomically but we didn't go that far in the instructions.  The call should either overwrite data and be safe to call multiple times or it should fail on overwrite due to an integrity error, just document your design choice
thanks!
Yeah I saw that. Seems really inefficient for very large data sets but I think I'll go with that assumption that we can just drop all of our records and recreate them. Thanks.
======================================================================
nsert into DimDate - sqlite DB
I've been stuck on this point for sometime, hoping that you can help me get unstuck.
I've been proceeding with a sqlite DB, and have been working on the load_reviews management command. I'm attempting to use 
DimDate.objects.bulk_create(
and it looks like the DB is complaining that a primary key isn't provided. I've also tried using DimDate.objects.update_or_create(
The handle routine I have is:
    def handle(self, *args, **options):

        dtypes = {'review_id': object, 'user_id': object, 'business_id': object, 'stars': float, 'date': object,
                  'text': object, 'useful': float, 'funny': float, 'cool': float}
        ddf = dd.read_csv('data/*.csv', dtype=dtypes, parse_dates=['date'])
        ddf.dropna(subset=['date'])
        DimDate.objects.bulk_create([x[1][4] for x in ddf.iterrows()])
The traceback is:
 bash-3.2$ python manage.py load_reviews
Traceback (most recent call last):
  File "manage.py", line 30, in <module>
    execute_from_command_line(sys.argv)
  File "/Users/davepacia/.local/share/virtualenvs/pset-6-dpacia-_t6rLTc3/lib/python3.7/site-packages/django/core/management/__init__.py", line 381, in execute_from_command_line
    utility.execute()
  File "/Users/davepacia/.local/share/virtualenvs/pset-6-dpacia-_t6rLTc3/lib/python3.7/site-packages/django/core/management/__init__.py", line 375, in execute
    self.fetch_command(subcommand).run_from_argv(self.argv)
  File "/Users/davepacia/.local/share/virtualenvs/pset-6-dpacia-_t6rLTc3/lib/python3.7/site-packages/django/core/management/base.py", line 323, in run_from_argv
    self.execute(*args, **cmd_options)
  File "/Users/davepacia/.local/share/virtualenvs/pset-6-dpacia-_t6rLTc3/lib/python3.7/site-packages/django/core/management/base.py", line 364, in execute
    output = self.handle(*args, **options)
  File "/Users/davepacia/Documents/advpython/pset-6-dpacia/src/yelp_reviews/management/commands/load_reviews.py", line 21, in handle
    DimDate.objects.bulk_create([x[1][4] for x in ddf.iterrows()])
  File "/Users/davepacia/.local/share/virtualenvs/pset-6-dpacia-_t6rLTc3/lib/python3.7/site-packages/django/db/models/manager.py", line 82, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/Users/davepacia/.local/share/virtualenvs/pset-6-dpacia-_t6rLTc3/lib/python3.7/site-packages/django/db/models/query.py", line 464, in bulk_create
    self._populate_pk_values(objs)
  File "/Users/davepacia/.local/share/virtualenvs/pset-6-dpacia-_t6rLTc3/lib/python3.7/site-packages/django/db/models/query.py", line 427, in _populate_pk_values
    if obj.pk is None:
AttributeError: 'Timestamp' object has no attribute 'pk'
You can't go directly from a panda datetime to a Django model object.  You need to instanciate the DimDate objects
==============================================================================
class ByYearSerializer and ByYear - Pset 6 Analytics Section
A few questions:
a) There is a comment "Return the averages....".
Which class method should be used to return serialized values in the ByYearSerializer class?
My understanding is limited to class Meta where one specifies the model, and the fields that need to be serialized.
b) Should the ByYearSerializer class inherit from (ModelSerializer) to be consistent with class ModelViewSet. It's not clear to me when Serializer should be used, and when ModelSerializer should be used.
c)  In the class ByYear, I am setting "serializer_class = ByYearSerializer". On the "return out_queryset" does DRF invoke ByYearSerializer instance? I am trying to understand the sequence of calls.
The following may not be accurate, but hope it is helpful:
a) ByYearSerializer is a serializer used by ByYear. Since ByYear itself is not a view directly based on Model but on a customized queryset, its serializer is like a "vanilla" one (subclass serializers.Serializer), not one that is a subclass of ModelSerializer (which is a shortcut to create serializer). See below for the difference:
https://www.django-rest-framework.org/api-guide/serializers/
https://www.django-rest-framework.org/tutorial/1-serialization/
https://www.django-rest-framework.org/tutorial/6-viewsets-and-routers/
b) Explained above.
c) Have to invoke get_queryset within ByYear. Check the format of FactViewSet or DateViewSet.
Thank you Yue. Your explanation on a) makes sense.
I am using get_queryset() in class ByYear. I am still not clear on what method should be invoked in class ByYearSerializer to serialize the queryset.
For the sake of testing, I have a built a simple database query like:
out_queryset = FactReview.objects.filter(date__year='2015).aggregate(stars=Avg('stars'))
The format of out_queryset is a dict {'stars': 3.6710301650540695}
(the numbers 3.67 is the average stars for the year 2015)
To serialize out_queryset, what needs to be done in BySerializer? 
If I populate Class BySerializer(..): with stars = Serializer.IngerField(..), this is not working.
I get errors like "TypeError: unhashable type: 'slice" when I try to browse the ByYear API. 
The error says "unhashable". It is because of the dictionary, which is mutable. I think the reason is that 'aggregate' is a terminal clause which returns a dictionary, but serializer expects a queryset. Use 'annotate' instead of 'aggregate'. For details, see below:
https://docs.djangoproject.com/en/2.2/topics/db/aggregation/#generating-aggregates-over-a-queryset
https://docs.djangoproject.com/en/2.2/topics/db/aggregation/#generating-aggregates-for-each-item-in-a-queryset
In addition, there seem to have two issues in your stuff: (1) stars should be float in serializer; (2) FactReview table (Model) should have daily summary statistics,  thus Avg should not work in that Thanks Yue !!  Annotate is the way to go. I overlooked the "set" data structure in queryset :-)
This leaves me wondering when ".aggregate" should be used, as they don't work with serializers (due to return of type dict with .aggregate),  and you can't generate representations (to view in the browsers as an example). My knowledge of Django is a few days old, so I am sure I am missing a number of things here.
[Scott Gorlin]
Scott Gorlin
11 days ago Aggregate operates on the entire query set vs annotate is per row of output. Serializers work just fine for both but what you're missing is that aggregate returns one object vs multiple the way we're using it here. I believe serializers have a many= kwarg to help with that
@Amit, Django is also new to me. Happy my reply helps, though it's not  accurate. 
tutorial for modelviewset, views and routers:
http://polyglot.ninja/django-rest-framework-viewset-modelviewset-router/
values section at: https://docs.djangoproject.com/en/2.2/topics/db/aggregation/
============================================================================================================================
[API Analytiics ]Django Aggregation models wehn using SQLlite
Hi, 
When I try to do aggregations with the Sqlite DB using django i get an error that it is not possible to use it because sqlite save dates as string. I have tried many ways to use only django model module to build the GET request on the API. 
Can I add a column in the review model with only the year? what can i do to keep using django model and get full credit, I cant find a 100% django models solution for this. 
1) yes you can build that as part of the star schema but 2) it works just fine in sqllite for me so i think you have a different issue
================================================================================================================================
If you'd like, add this to config.settings.base to speed up browsing:

REST_FRAMEWORK = {
'DEFAULT_PAGINATION_CLASS': 'rest_framework.pagination.LimitOffsetPagination',
'PAGE_SIZE': 10
}
============================================================================================

 

 

